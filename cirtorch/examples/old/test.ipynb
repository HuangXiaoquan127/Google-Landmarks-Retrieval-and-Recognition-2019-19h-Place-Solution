{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "import argparse\nimport os\nimport time\nimport pickle\nimport pdb\n\nimport numpy as np\n\nimport torch\nfrom torch.utils.model_zoo import load_url\nfrom torch.autograd import Variable\nfrom torchvision import transforms\n\nfrom cirtorch.networks.imageretrievalnet import init_network, extract_vectors\nfrom cirtorch.datasets.datahelpers import cid2filename\nfrom cirtorch.datasets.testdataset import configdataset\nfrom cirtorch.utils.download import download_train, download_test\nfrom cirtorch.utils.whiten import whitenlearn, whitenapply, pcawhitenlearn\nfrom cirtorch.utils.evaluate import compute_map_and_print\nfrom cirtorch.utils.general import get_data_root, htime\n# hxq added\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nfrom scipy import ndimage\nimport math\nfrom cirtorch.datasets.landmarks_downloader import ParseData\nimport csv\nfrom cirtorch.utils.diffussion import *\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "PRETRAINED \u003d {\n    \u0027retrievalSfM120k-vgg16-gem\u0027        : \u0027http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/retrievalSfM120k-vgg16-gem-b4dcdc6.pth\u0027,\n    \u0027retrievalSfM120k-resnet101-gem\u0027    : \u0027http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/retrievalSfM120k-resnet101-gem-b80fb85.pth\u0027,\n}\n\ndatasets_names \u003d [\u0027oxford5k\u0027, \u0027paris6k\u0027, \u0027roxford5k\u0027, \u0027rparis6k\u0027, \u0027google-landmarks-dataset-resize-test\u0027,\n                  \u0027google-landmarks-dataset-v2-test\u0027]\nwhitening_names \u003d [\u0027retrieval-SfM-30k\u0027, \u0027retrieval-SfM-120k\u0027]\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "test_datasets \u003d \u0027google-landmarks-dataset-v2-test\u0027\n\ngpu_id \u003d \u00273\u0027\n\n# network_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-pytorch/trained_network/retrieval-SfM-120k_resnet101_gem_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize362/model_epoch98.pth.tar\u0027\n# network_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_F_GL/google-landmarks-dataset-resize_resnet101_gem_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize362/model_epoch100.pth.tar\u0027\n# network_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_O_GL_FC/google-landmarks-dataset-resize_resnet101_gem_whiten_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize362/model_epoch114.pth.tar\u0027\nnetwork_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_O_GL_FC_multigem/google-landmarks-dataset-resize_resnet101_multigem_whiten_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize362/model_epoch100.pth.tar\u0027\n# network_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_O_120k_FC_multigem/retrieval-SfM-120k_resnet101_multigem_whiten_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize650/model_epoch101.pth.tar\u0027\n\nparams \u003d [{\u0027ms\u0027: [1], \u0027image_size\u0027: [256, 362, 512, 768, 1024, 1280, float(\u0027inf\u0027)], \u0027pac_dims\u0027: [2048, 1536, 1024, 512]},\n          {\u0027ms\u0027: [1, 1/2**(1/2), 1/2], \u0027image_size\u0027: [1024], \u0027pac_dims\u0027: [2048, 1536, 1024, 512]},\n          {\u0027ms\u0027: [1, 1/2**(1/2), 2**(1/2)], \u0027image_size\u0027: [1024], \u0027pac_dims\u0027: [2048, 1536, 1024, 512, 128, 96, 64, 32]}]\n\nwhitening \u003d \u0027google-landmarks-dataset-v2-test\u0027\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# check if there are unknown datasets\nfor dataset in test_datasets.split(\u0027,\u0027):\n    if dataset not in datasets_names:\n        raise ValueError(\u0027Unsupported or unknown dataset: {}!\u0027.format(dataset))\n# setting up the visible GPU\nos.environ[\u0027CUDA_VISIBLE_DEVICES\u0027] \u003d gpu_id\n# loading network from path\nif network_path is not None:\n\n    print(\"\u003e\u003e Loading network:\\n\u003e\u003e\u003e\u003e \u0027{}\u0027\".format(network_path))\n    if network_path in PRETRAINED:\n        # pretrained networks (downloaded automatically)\n        state \u003d load_url(PRETRAINED[network_path], model_dir\u003dos.path.join(get_data_root(), \u0027networks\u0027))\n    else:\n        # fine-tuned network from path\n        state \u003d torch.load(network_path)\n\n    # parsing net params from meta\n    # architecture, pooling, mean, std required\n    # the rest has default values, in case that is doesnt exist\n    net_params \u003d {}\n    net_params[\u0027architecture\u0027] \u003d state[\u0027meta\u0027][\u0027architecture\u0027]\n    net_params[\u0027pooling\u0027] \u003d state[\u0027meta\u0027][\u0027pooling\u0027]\n    net_params[\u0027local_whitening\u0027] \u003d state[\u0027meta\u0027].get(\u0027local_whitening\u0027, False)\n    net_params[\u0027regional\u0027] \u003d state[\u0027meta\u0027].get(\u0027regional\u0027, False)\n    net_params[\u0027whitening\u0027] \u003d state[\u0027meta\u0027].get(\u0027whitening\u0027, False)\n    net_params[\u0027mean\u0027] \u003d state[\u0027meta\u0027][\u0027mean\u0027]\n    net_params[\u0027std\u0027] \u003d state[\u0027meta\u0027][\u0027std\u0027]\n    net_params[\u0027pretrained\u0027] \u003d False\n    net_params[\u0027multi_layer_cat\u0027] \u003d state[\u0027meta\u0027][\u0027multi_layer_cat\u0027]\n\n    # load network\n    net \u003d init_network(net_params)\n    net.load_state_dict(state[\u0027state_dict\u0027])\n    \n    # if whitening is precomputed\n    if \u0027Lw\u0027 in state[\u0027meta\u0027]:\n        net.meta[\u0027Lw\u0027] \u003d state[\u0027meta\u0027][\u0027Lw\u0027]\n    \n    print(\"\u003e\u003e\u003e\u003e loaded network: \")\n    print(net.meta_repr())\n    \n# moving network to gpu and eval mode\nnet.cuda()\nnet.eval()\n\n# set up the transform\nnormalize \u003d transforms.Normalize(\n    mean\u003dnet.meta[\u0027mean\u0027],\n    std\u003dnet.meta[\u0027std\u0027]\n)\ntransform \u003d transforms.Compose([\n    transforms.ToTensor(),\n    normalize\n])\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "start \u003d time.time()\nprint(\u0027\u003e\u003e {}: Extracting...\u0027.format(dataset))\n\n# prepare config structure for the test dataset\ncfg \u003d configdataset(dataset, os.path.join(get_data_root(), \u0027test\u0027))\nimages \u003d [cfg[\u0027im_fname\u0027](cfg,i) for i in range(cfg[\u0027n\u0027])]\nqimages \u003d [cfg[\u0027qim_fname\u0027](cfg,i) for i in range(cfg[\u0027nq\u0027])]\n# bbxs \u003d [tuple(cfg[\u0027gnd\u0027][i][\u0027bbx\u0027]) for i in range(cfg[\u0027nq\u0027])]\nprint(\u0027\u003e\u003e not use bbxs...\u0027)\nbbxs \u003d None\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "for param in params:\n    for image_size in param[\u0027image_size\u0027]:\n        # setting up the multi-scale parameters\n        print(\"\u003e\u003e image size: {}\".format(image_size))\n        if len(param[\u0027ms\u0027])\u003e1 and net.meta[\u0027pooling\u0027] \u003d\u003d \u0027gem\u0027 \\\n                and not net.meta[\u0027regional\u0027] and not net.meta[\u0027whitening\u0027]:\n            msp \u003d net.pool.p.item()\n            print(\"\u003e\u003e Set-up multiscale:\")\n            print(\"\u003e\u003e\u003e\u003e ms: {}\".format(param[\u0027ms\u0027]))            \n            print(\"\u003e\u003e\u003e\u003e msp: {}\".format(msp))\n        else:\n            msp \u003d 1\n            print(\"\u003e\u003e Set-up multiscale:\")\n            print(\"\u003e\u003e\u003e\u003e ms: {}\".format(param[\u0027ms\u0027]))\n            print(\"\u003e\u003e\u003e\u003e msp: {}\".format(msp))\n            \n        # extract database and query vectors\n        print(\u0027\u003e\u003e {}: database images...\u0027.format(dataset))\n        vecs \u003d extract_vectors(net, images, image_size, transform, ms\u003dparam[\u0027ms\u0027], msp\u003dmsp)\n        print(\u0027\u003e\u003e {}: query images...\u0027.format(dataset))\n        qvecs \u003d extract_vectors(net, qimages, image_size, transform, bbxs\u003dbbxs, ms\u003dparam[\u0027ms\u0027], msp\u003dmsp)\n        print(\u0027\u003e\u003e {}: Evaluating...\u0027.format(dataset))\n        # convert to numpy\n        vecs \u003d vecs.numpy()\n        qvecs \u003d qvecs.numpy()\n        # search, rank, and print\n        scores \u003d np.dot(vecs.T, qvecs)\n        ranks \u003d np.argsort(-scores, axis\u003d0)\n        qvecs_orig \u003d qvecs\n        ranks_orig \u003d ranks\n        mismatched_info \u003d compute_map_and_print(dataset, ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n        \n        # compute whitening\n        if whitening is not None:\n            start \u003d time.time()\n            if \u0027Lw\u0027 in net.meta and whitening in net.meta[\u0027Lw\u0027]:\n                print(\u0027\u003e\u003e {}: Whitening is precomputed, loading it...\u0027.format(whitening))\n                if len(param[\u0027ms\u0027]) \u003e 1:\n                    Lw \u003d net.meta[\u0027Lw\u0027][whitening][\u0027ms\u0027]\n                else:\n                    Lw \u003d net.meta[\u0027Lw\u0027][whitening][\u0027ss\u0027]\n            else:\n                # if we evaluate networks from path we should save/load whitening\n                # not to compute it every time\n                if network_path is not None:\n                    whiten_fn \u003d network_path + \u0027_{}_whiten\u0027.format(whitening)\n                    if len(param[\u0027ms\u0027]) \u003e 1:\n                        whiten_fn +\u003d \u0027_ms\u0027\n                    whiten_fn +\u003d \u0027.pth\u0027\n                else:\n                    whiten_fn \u003d None\n                if whiten_fn is not None and os.path.isfile(whiten_fn):\n                    print(\u0027\u003e\u003e {}: Whitening is precomputed, loading it...\u0027.format(whitening))\n                    Lw \u003d torch.load(whiten_fn)\n                else:\n                    print(\u0027\u003e\u003e {}: Learning whitening...\u0027.format(whitening))\n                    # extract whitening vectors\n                    print(\u0027\u003e\u003e {}: Extracting...\u0027.format(whitening))\n                    # wvecs \u003d vecs\n                    wvecs \u003d np.hstack((vecs, qvecs))\n                    # learning whitening\n                    print(\u0027\u003e\u003e {}: Learning...\u0027.format(whitening))\n                    m, P \u003d pcawhitenlearn(wvecs)\n                    # m, P \u003d whitenlearn(wvecs)                    \n                    Lw \u003d {\u0027m\u0027: m, \u0027P\u0027: P}\n                    # saving whitening if whiten_fn exists\n                    if whiten_fn is not None:\n                        print(\u0027\u003e\u003e {}: Saving to {}...\u0027.format(whitening, whiten_fn))\n                        # torch.save(Lw, whiten_fn)\n            print(\u0027\u003e\u003e {}: elapsed time: {}\u0027.format(whitening, htime(time.time() - start)))\n        else:\n            Lw \u003d None\n        \n        if Lw is not None:\n            for dim in param[\u0027pac_dims\u0027]:\n                print(\u0027\u003e\u003e\u003e\u003e pac_dim: {}\u0027.format(dim))\n                # whiten the vectors\n                vecs_lw  \u003d whitenapply(vecs, Lw[\u0027m\u0027], Lw[\u0027P\u0027], dim)\n                qvecs_lw \u003d whitenapply(qvecs, Lw[\u0027m\u0027], Lw[\u0027P\u0027], dim)\n                \n                # search, rank, and print\n                scores \u003d np.dot(vecs_lw.T, qvecs_lw)\n                ranks_lw \u003d np.argsort(-scores, axis\u003d0)\n                qvecs_lw_orig \u003d qvecs_lw\n                ranks_lw_orig \u003d ranks_lw\n                mismatched_info \u003d compute_map_and_print(dataset + \u0027 + whiten\u0027, ranks_lw, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# save vecs, qvecs, ranks to pickle\nimport pickle\nfile_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/test_vecs/R101_O_GL_FC_multigem/vecs_qvecs.pkl\u0027\nwith open(file_path, \u0027wb\u0027) as f:\n    pickle.dump((vecs, qvecs, ranks), f)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# load vecs, qvecs, ranks from pickle\nimport pickle\nfile_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/test_vecs/R101_O_GL_FC_multigem/vecs_qvecs.pkl\u0027\nwith open(file_path, \u0027rb\u0027) as f:\n    (vecs, qvecs, ranks) \u003d pickle.load(f)\nqvecs_orig \u003d qvecs\nranks_orig \u003d ranks\nmismatched_info \u003d compute_map_and_print(dataset, ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\n\n# save vecs_lw, qvecs_lw, ranks_lw to pickle\nimport pickle\nfile_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/test_vecs/R101_O_GL_FC_multigem/vecs_lw_qvecs_lw.pkl\u0027\nwith open(file_path, \u0027wb\u0027) as f:\n    pickle.dump((vecs_lw, qvecs_lw, ranks_lw), f)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# load vecs, qvecs, ranks from pickle\nimport pickle\nfile_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/test_vecs/R101_O_GL_FC_multigem/vecs_lw_qvecs_lw.pkl\u0027\nwith open(file_path, \u0027rb\u0027) as f:\n    (vecs_lw, qvecs_lw, ranks_lw) \u003d pickle.load(f)\nqvecs_lw_orig \u003d qvecs_lw\nranks_lw_orig \u003d ranks_lw\nmismatched_info \u003d compute_map_and_print(dataset, ranks_lw, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# find the best k for query expansion\nks \u003d list(range(1, int(10317 / 491) + 1))\nranks_split_num \u003d 1\nfor k in ks:\n    QE_weight \u003d (np.arange(k, 0, -1) / k).reshape(1, k, 1)\n    print(\u0027\u003e\u003e query expansion top k: {}\u0027.format(k))\n    for i in range(ranks_split_num):\n        ranks_split \u003d ranks[:k, int(ranks.shape[1] / ranks_split_num * i):\n                               int(ranks.shape[1] / ranks_split_num * (i + 1))]\n        top_k_vecs \u003d vecs[:, ranks_split]  # shape \u003d (2048, k, query_split_size)\n        qvecs_temp \u003d (top_k_vecs * QE_weight).sum(axis\u003d1)\n        qvecs_temp \u003d qvecs_temp / (np.linalg.norm(qvecs_temp, ord\u003d2, axis\u003d0, keepdims\u003dTrue) + 1e-6)\n        if i \u003d\u003d 0:\n            qvecs \u003d qvecs_temp\n        else:\n            qvecs \u003d np.hstack((qvecs, qvecs_temp))\n        print(\u0027\\r\u003e\u003e\u003e\u003e calculate new query vectors {}/{} done...\u0027.format(i+1, ranks_split_num), end\u003d\u0027\u0027)\n    print(\u0027\u0027)\n    # search, rank, and print\n    scores \u003d np.dot(vecs.T, qvecs)\n    ranks \u003d np.argsort(-scores, axis\u003d0)\n    mismatched_info \u003d compute_map_and_print(dataset, ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n    # recover the original value\n    qvecs \u003d qvecs_orig\n    ranks \u003d ranks_orig\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# Query expansion\nk \u003d 8\nalpha \u003d 8./2\niters \u003d 6\nranks_split_num \u003d 1\nfor iter in range(iters):\n    print(\u0027\u003e\u003e Query expansion: k: {}, alpha: {}, iteration: {}\u0027.format(k, alpha, iter+1))\n    QE_weight \u003d (np.arange(k, 0, -1) / k).reshape(1, k, 1)\n    for i in range(ranks_split_num):\n        ranks_split \u003d ranks[:k, int(ranks.shape[1] / ranks_split_num * i):\n                                int(ranks.shape[1] / ranks_split_num * (i + 1))]\n        top_k_vecs \u003d vecs[:, ranks_split]  # shape \u003d (2048, k, query_split_size)\n        qvecs_temp \u003d (top_k_vecs * (QE_weight ** alpha)).sum(axis\u003d1)\n        # qvecs_temp +\u003d qvecs\n        qvecs_temp \u003d qvecs_temp / (np.linalg.norm(qvecs_temp, ord\u003d2, axis\u003d0, keepdims\u003dTrue) + 1e-6)\n        if i \u003d\u003d 0:\n            qvecs \u003d qvecs_temp\n        else:\n            qvecs \u003d np.hstack((qvecs, qvecs_temp))\n        print(\u0027\\r\u003e\u003e\u003e\u003e calculate new query vectors {}/{} done...\u0027.format(i+1, ranks_split_num), end\u003d\u0027\u0027)\n    print(\u0027\u0027)\n    # k +\u003d 1\n    # search, rank, and print\n    scores \u003d np.dot(vecs.T, qvecs)\n    ranks \u003d np.argsort(-scores, axis\u003d0)\n    mismatched_info \u003d compute_map_and_print(dataset, ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n# recover the original value\nqvecs \u003d qvecs_orig\nranks \u003d ranks_orig\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# looking for the best pca and query expansion combination parameter\nfor dim in [2048]:\n    print(\u0027\u003e\u003e\u003e\u003e pac_dim: {}\u0027.format(dim))\n    # whiten the vectors\n    vecs_lw \u003d whitenapply(vecs, Lw[\u0027m\u0027], Lw[\u0027P\u0027], dim)\n    qvecs_lw \u003d whitenapply(qvecs, Lw[\u0027m\u0027], Lw[\u0027P\u0027], dim)\n\n    # search, rank, and print\n    scores \u003d np.dot(vecs_lw.T, qvecs_lw)\n    ranks_lw \u003d np.argsort(-scores, axis\u003d0)\n    qvecs_lw_orig \u003d qvecs_lw\n    ranks_lw_orig \u003d ranks_lw\n    mismatched_info \u003d compute_map_and_print(dataset + \u0027 + whiten\u0027, ranks_lw, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\n    ks \u003d [15]\n    alphas \u003d [12./2]\n    iters \u003d 6\n    ranks_split_num \u003d 1\n    for k in ks:\n        for alpha in alphas:\n            for iter in range(iters):\n                print(\u0027\u003e\u003e Query expansion: k: {}, alpha: {}, iteration: {}\u0027.format(k, alpha, iter+1))\n                QE_weight \u003d (np.arange(k, 0, -1) / k).reshape(1, k, 1)\n                for i in range(ranks_split_num):\n                    ranks_split \u003d ranks_lw[:k, int(ranks_lw.shape[1] / ranks_split_num * i):\n                                            int(ranks_lw.shape[1] / ranks_split_num * (i + 1))]\n                    top_k_vecs \u003d vecs[:, ranks_split]  # shape \u003d (2048, k, query_split_size)\n                    qvecs_temp \u003d (top_k_vecs * (QE_weight ** alpha)).sum(axis\u003d1)\n                    # qvecs_temp +\u003d qvecs\n                    qvecs_temp \u003d qvecs_temp / (np.linalg.norm(qvecs_temp, ord\u003d2, axis\u003d0, keepdims\u003dTrue) + 1e-6)\n                    if i \u003d\u003d 0:\n                        qvecs_lw \u003d qvecs_temp\n                    else:\n                        qvecs_lw \u003d np.hstack((qvecs_lw, qvecs_temp))\n                    print(\u0027\\r\u003e\u003e\u003e\u003e calculate new query vectors {}/{} done...\u0027.format(i+1, ranks_split_num), end\u003d\u0027\u0027)\n                print(\u0027\u0027)\n                # k +\u003d 1\n                # search, rank, and print\n                scores \u003d np.dot(vecs.T, qvecs_lw)\n                ranks_lw \u003d np.argsort(-scores, axis\u003d0)\n                mismatched_info \u003d compute_map_and_print(dataset, ranks_lw, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n            # recover the original value\n            qvecs_lw \u003d qvecs_lw_orig\n            ranks_lw \u003d ranks_lw_orig\n            print(\u0027\u0027)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# diffussion\nvecs_lw \u003d whitenapply(vecs, Lw[\u0027m\u0027], Lw[\u0027P\u0027], dim)\nqvecs_lw \u003d whitenapply(qvecs, Lw[\u0027m\u0027], Lw[\u0027P\u0027], dim)\n# qvecs_lw \u003d qvecs_lw_orig\n# ranks_lw \u003d ranks_lw_orig\nQ \u003d qvecs_lw\nX \u003d vecs_lw\nK \u003d 100 # approx 50 mutual nns\nQUERYKNN \u003d 10\nR \u003d 2000\nalpha \u003d 0.9\n\n# search, rank, and print\nsim  \u003d np.dot(X.T, Q)\nqsim \u003d sim_kernel(sim).T\n\nsortidxs \u003d np.argsort(-qsim, axis \u003d 1)\nfor i in range(len(qsim)):\n    qsim[i,sortidxs[i,QUERYKNN:]] \u003d 0\n\nqsim \u003d sim_kernel(qsim)\nA \u003d np.dot(X.T, X)\nW \u003d sim_kernel(A).T\nW \u003d topK_W(W, K)\nWn \u003d normalize_connection_graph(W)\n\nplain_ranks \u003d np.argsort(-sim, axis\u003d0)\nmismatched_info \u003d compute_map_and_print(dataset + \u0027 + whiten\u0027, plain_ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\ncg_ranks \u003d  cg_diffusion(qsim, Wn, alpha)\nmismatched_info \u003d compute_map_and_print(dataset + \u0027 + whiten\u0027, cg_ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\ncg_trunk_ranks \u003d  dfs_trunk(sim, A, alpha \u003d alpha, QUERYKNN \u003d QUERYKNN )\nmismatched_info \u003d compute_map_and_print(dataset + \u0027 + whiten\u0027, cg_trunk_ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\nfast_spectral_ranks \u003d fsr_rankR(qsim, Wn, alpha, R)\nmismatched_info \u003d compute_map_and_print(dataset + \u0027 + whiten\u0027, fast_spectral_ranks, cfg[\u0027gnd\u0027], kappas\u003d[1, 5, 10, 100])\n\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "pycharm-68d9976a",
      "language": "python",
      "display_name": "PyCharm (cnnimageretrieval-end2end-google_landmarks_retrieval)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}