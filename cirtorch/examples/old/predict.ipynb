{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-1-a0be885f0a1c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcirtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimageretrievalnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcirtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatahelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcid2filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcirtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfigdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named \u0027cirtorch\u0027"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named \u0027cirtorch\u0027",
          "output_type": "error"
        }
      ],
      "source": "import argparse\nimport os\nimport time\nimport pickle\nimport pdb\n\nimport numpy as np\n\nimport torch\nfrom torch.utils.model_zoo import load_url\nfrom torch.autograd import Variable\nfrom torchvision import transforms\n\nfrom cirtorch.networks.imageretrievalnet import init_network, extract_vectors\nfrom cirtorch.datasets.datahelpers import cid2filename\nfrom cirtorch.datasets.testdataset import configdataset\nfrom cirtorch.utils.download import download_train, download_test\nfrom cirtorch.utils.whiten import whitenlearn, whitenapply, pcawhitenlearn\nfrom cirtorch.utils.evaluate import compute_map_and_print\nfrom cirtorch.utils.general import get_data_root, htime\n\n# hxq added\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nfrom scipy import ndimage\nimport math\nimport csv\nimport random\nimport gc\nfrom cirtorch.datasets.datahelpers import clear_no_exist\n# import faiss"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "PRETRAINED \u003d {\n    \u0027retrievalSfM120k-vgg16-gem\u0027        : \u0027http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/retrievalSfM120k-vgg16-gem-b4dcdc6.pth\u0027,\n    \u0027retrievalSfM120k-resnet101-gem\u0027    : \u0027http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/retrievalSfM120k-resnet101-gem-b80fb85.pth\u0027,\n}\ndatasets_names \u003d [\u0027oxford5k\u0027, \u0027paris6k\u0027, \u0027roxford5k\u0027, \u0027rparis6k\u0027,\n                  \u0027google-landmarks-dataset-resize\u0027, \u0027google-landmarks-dataset\u0027, \u0027google-landmarks-dataset-v2\u0027]\n# whitening_names \u003d [\u0027retrieval-SfM-30k\u0027, \u0027retrieval-SfM-120k\u0027]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "dataset \u003d \u0027google-landmarks-dataset\u0027\n\ngpu_id \u003d \u00273\u0027\n\n# network_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_F_GL/google-landmarks-dataset-resize_resnet101_gem_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize362/model_epoch100.pth.tar\u0027\nnetwork_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_O_GL_FC/google-landmarks-dataset-resize_resnet101_gem_whiten_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize362/model_epoch114.pth.tar\u0027\n# network_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_O_GL_FC_multigem/google-landmarks-dataset-resize_resnet101_multigem_whiten_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize362/model_epoch100.pth.tar\u0027\n# network_path \u003d \u0027/media/iap205/Data/Export/cnnimageretrieval-google_landmark_retrieval/trained_network/R101_O_120k_FC_multigem/retrieval-SfM-120k_resnet101_multigem_whiten_contrastive_m0.85_adam_lr5.0e-07_wd1.0e-04_nnum5_qsize2000_psize22000_bsize5_imsize650/model_epoch101.pth.tar\u0027\n\nimage_size \u003d 1024\n\n# multiscale \u003d \u0027[1]\u0027\n# multiscale \u003d \u0027[1, 1/2**(1/2), 1/2]\u0027\nmultiscale \u003d \u0027[1, 1/2**(1/2), 2**(1/2)]\u0027\n# multiscale \u003d \u0027[1, 0.875, 0.75]\u0027\n# multiscale \u003d \u0027[256/1600*(2**(1/2)),256/1600,256/1600*(2**(1/2))*(1/2)]\u0027\n\nwhitening \u003d \u0027google-landmarks-dataset\u0027\n# whitening \u003d \u0027google-landmarks-dataset-resize\u0027\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# check if there are unknown datasets\nif dataset not in datasets_names:\n    raise ValueError(\u0027Unsupported or unknown dataset: {}!\u0027.format(dataset))\n\n# setting up the visible GPU\nos.environ[\u0027CUDA_VISIBLE_DEVICES\u0027] \u003d gpu_id\n\n# loading network from path\nprint(\"\u003e\u003e Loading network:\\n\u003e\u003e\u003e\u003e \u0027{}\u0027\".format(network_path))\nif network_path in PRETRAINED:\n    # pretrained networks (downloaded automatically)\n    state \u003d load_url(PRETRAINED[network_path], model_dir\u003dos.path.join(get_data_root(), \u0027networks\u0027))\nelse:\n    # fine-tuned network from path\n    state \u003d torch.load(network_path)\n# parsing net params from meta\n# architecture, pooling, mean, std required\n# the rest has default values, in case that is doesnt exist\nnet_params \u003d {}\nnet_params[\u0027architecture\u0027] \u003d state[\u0027meta\u0027][\u0027architecture\u0027]\nnet_params[\u0027pooling\u0027] \u003d state[\u0027meta\u0027][\u0027pooling\u0027]\nnet_params[\u0027local_whitening\u0027] \u003d state[\u0027meta\u0027].get(\u0027local_whitening\u0027, False)\nnet_params[\u0027regional\u0027] \u003d state[\u0027meta\u0027].get(\u0027regional\u0027, False)\nnet_params[\u0027whitening\u0027] \u003d state[\u0027meta\u0027].get(\u0027whitening\u0027, False)\nnet_params[\u0027mean\u0027] \u003d state[\u0027meta\u0027][\u0027mean\u0027]\nnet_params[\u0027std\u0027] \u003d state[\u0027meta\u0027][\u0027std\u0027]\nnet_params[\u0027pretrained\u0027] \u003d False\nnet_params[\u0027multi_layer_cat\u0027] \u003d state[\u0027meta\u0027][\u0027multi_layer_cat\u0027]\n# load network\nnet \u003d init_network(net_params)\nnet.load_state_dict(state[\u0027state_dict\u0027])\n\n# if whitening is precomputed\nif \u0027Lw\u0027 in state[\u0027meta\u0027]:\n    net.meta[\u0027Lw\u0027] \u003d state[\u0027meta\u0027][\u0027Lw\u0027]\n\nprint(\"\u003e\u003e\u003e\u003e loaded network: \")\nprint(net.meta_repr())\n\nprint(\"\u003e\u003e image size: {}\".format(image_size))\n# setting up the multi-scale parameters\nms \u003d list(eval(multiscale))\nif len(ms)\u003e1 and net.meta[\u0027pooling\u0027] \u003d\u003d \u0027gem\u0027 and not net.meta[\u0027regional\u0027] and not net.meta[\u0027whitening\u0027]:\n    msp \u003d net.pool.p.item()\n    print(\"\u003e\u003e Set-up multiscale:\")\n    print(\"\u003e\u003e\u003e\u003e ms: {}\".format(ms))            \n    print(\"\u003e\u003e\u003e\u003e msp: {}\".format(msp))\nelse:\n    msp \u003d 1\n\n# moving network to gpu and eval mode\nnet.cuda()\nnet.eval()\n\n# set up the transform\nnormalize \u003d transforms.Normalize(\n    mean\u003dnet.meta[\u0027mean\u0027],\n    std\u003dnet.meta[\u0027std\u0027]\n)\ntransform \u003d transforms.Compose([\n    transforms.ToTensor(),\n    normalize\n])\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "start \u003d time.time()\nprint(\u0027\u003e\u003e {}: Extracting...\u0027.format(dataset))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e Prepare data information...\u0027)\nif dataset \u003d\u003d \u0027google-landmarks-dataset\u0027:\n    index_file_path \u003d os.path.join(get_data_root(), \u0027index.csv\u0027)\n    index_mark_path \u003d os.path.join(get_data_root(), \u0027index_mark.csv\u0027)\n    index_miss_path \u003d os.path.join(get_data_root(), \u0027index_miss.csv\u0027)\n    index_img_path \u003d os.path.join(get_data_root(), \u0027index\u0027)\n    test_file_path \u003d os.path.join(get_data_root(), \u0027test.csv\u0027)\n    test_mark_path \u003d os.path.join(get_data_root(), \u0027test_mark.csv\u0027)\n    test_mark_add_path \u003d os.path.join(get_data_root(), \u0027test_mark_add.csv\u0027)\n    test_miss_path \u003d os.path.join(get_data_root(), \u0027test_miss.csv\u0027)    \n    test_img_path \u003d os.path.join(get_data_root(), \u0027google-landmarks-dataset-test\u0027)\nelif dataset \u003d\u003d \u0027google-landmarks-dataset-resize\u0027:\n    index_file_path \u003d os.path.join(get_data_root(), \u0027index.csv\u0027)\n    index_mark_path \u003d os.path.join(get_data_root(), \u0027resize_index_mark.csv\u0027)\n    index_miss_path \u003d os.path.join(get_data_root(), \u0027resize_index_miss.csv\u0027)\n    index_img_path \u003d os.path.join(get_data_root(), \u0027resize_index_image\u0027)\n    test_file_path \u003d os.path.join(get_data_root(), \u0027test.csv\u0027)\n    test_mark_path \u003d os.path.join(get_data_root(), \u0027resize_test_mark.csv\u0027)\n    test_mark_add_path \u003d os.path.join(get_data_root(), \u0027resize_test_mark_add.csv\u0027)\n    test_miss_path \u003d os.path.join(get_data_root(), \u0027resize_test_miss.csv\u0027)   \n    test_img_path \u003d os.path.join(get_data_root(), \u0027resize_test_image\u0027)\nelif dataset \u003d\u003d \u0027google-landmarks-dataset-v2\u0027:\n    pass\nif not (os.path.isfile(index_mark_path) or os.path.isfile(index_miss_path)):\n    clear_no_exist(index_file_path, index_mark_path, index_miss_path, index_img_path)\nif not (os.path.isfile(test_mark_path) or os.path.isfile(test_miss_path)):\n    clear_no_exist(test_file_path, test_mark_path, test_miss_path, test_img_path)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e load index image path...\u0027)\nretrieval_other_dataset \u003d \u0027/home/iap205/Datasets/google-landmarks-dataset-resize\u0027\ncsvfile \u003d open(index_mark_path, \u0027r\u0027)\ncsvreader \u003d csv.reader(csvfile)\nimages \u003d []\nmiss, add \u003d 0, 0\nfor line in csvreader:\n    if line[0] \u003d\u003d \u00271\u0027:\n        images.append(os.path.join(index_img_path, line[1] + \u0027.jpg\u0027))\n    elif line[0] \u003d\u003d \u00270\u0027:\n        retrieval_img_path \u003d os.path.join(retrieval_other_dataset, \u0027resize_index_image\u0027, line[1] + \u0027.jpg\u0027)\n        if os.path.isfile(retrieval_img_path):\n            images.append(retrieval_img_path)\n            add +\u003d 1\n        miss +\u003d 1\ncsvfile.close()\nprint(\u0027\u003e\u003e\u003e\u003e index image miss: {}, supplement: {}, still miss: {}\u0027.format(miss, add, miss-add))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e load query image path...\u0027)\ncsvfile \u003d open(test_mark_path, \u0027r\u0027)\ncsvreader \u003d csv.reader(csvfile)\nsavefile \u003d open(test_mark_add_path, \u0027w\u0027)\nsave_writer \u003d csv.writer(savefile)\nqimages \u003d []\nmiss, add \u003d 0, 0\nfor line in csvreader:\n    if line[0] \u003d\u003d \u00271\u0027:\n        qimages.append(os.path.join(test_img_path, line[1] + \u0027.jpg\u0027))\n        save_writer.writerow(line)\n    elif line[0] \u003d\u003d \u00270\u0027:\n        retrieval_img_path \u003d os.path.join(retrieval_other_dataset, \u0027resize_test_image\u0027, line[1] + \u0027.jpg\u0027)\n        if os.path.isfile(retrieval_img_path):\n            qimages.append(retrieval_img_path)\n            save_writer.writerow([\u00271\u0027, line[1]])\n            add +\u003d 1\n        else:\n            save_writer.writerow(line)\n        miss +\u003d 1\ncsvfile.close()\nsavefile.close()\nprint(\u0027\u003e\u003e\u003e\u003e test image miss: {}, supplement: {}, still miss: {}\u0027.format(miss, add, miss - add))\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# extract index vectors\nprint(\u0027\u003e\u003e {}: database images...\u0027.format(dataset))\nsplit_num \u003d 8\nextract_num \u003d int(len(images) / split_num)\nnum_list \u003d list(range(0, len(images)+1, extract_num))\nnum_list[-1] \u003d len(images)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "part \u003d [0, 1]\nfor k in part:\n    print(\u0027\u003e\u003e\u003e\u003e extract part {} of {}\u0027.format(k+1, split_num))\n    vecs \u003d extract_vectors(net, images[num_list[k]:num_list[k+1]], image_size, transform, ms\u003dms, msp\u003dmsp)        \n    vecs \u003d vecs.numpy()\n    print(\u0027\u003e\u003e\u003e\u003e save index vecs to pkl...\u0027)\n    vecs_file_path \u003d os.path.join(get_data_root(), \u0027index_vecs{}_of_{}.pkl\u0027.format(k+1, split_num))\n    vecs_file \u003d open(vecs_file_path, \u0027wb\u0027)\n    pickle.dump(vecs, vecs_file)\n    vecs_file.close()\n    print(\u0027\u003e\u003e\u003e\u003e index_vecs{}_of_{}.pkl save done...\u0027.format(k+1, split_num))\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# extract query vectors\nprint(\u0027\u003e\u003e {}: query images...\u0027.format(dataset))\nsplit_num \u003d 8\nextract_num \u003d int(len(qimages) / split_num)\nnum_list \u003d list(range(0, len(qimages)+1, extract_num))\nnum_list[-1] \u003d len(qimages)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "part \u003d [0, 1]\nfor k in part:\n    print(\u0027\u003e\u003e\u003e\u003e extract part {} of {}\u0027.format(k+1, split_num))\n    qvecs \u003d extract_vectors(net, qimages[num_list[k]:num_list[k + 1]], image_size, transform, ms\u003dms, msp\u003dmsp)\n    qvecs \u003d qvecs.numpy()\n    print(\u0027\u003e\u003e\u003e\u003e save test vecs to pkl...\u0027)\n    qvecs_file_path \u003d os.path.join(get_data_root(), \u0027test_vecs{}_of_{}.pkl\u0027.format(k+1, split_num))\n    qvecs_file \u003d open(qvecs_file_path, \u0027wb\u0027)\n    pickle.dump(qvecs, qvecs_file)\n    qvecs_file.close()\n    print(\u0027\u003e\u003e\u003e\u003e test_vecs{}_of_{}.pkl save done...\u0027.format(k+1, split_num))\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e\u003e\u003e load index vecs from pkl...\u0027)\nsplit_num \u003d 8\nfor i in range(split_num):\n    # vecs_temp \u003d np.loadtxt(open(os.path.join(get_data_root(), \u0027index_vecs{}_of_{}.csv\u0027.format(i+1, split_num)), \"rb\"),\n    #                        delimiter\u003d\",\", skiprows\u003d0)\n    with open(os.path.join(get_data_root(), \u0027index_vecs{}_of_{}.pkl\u0027.format(i+1, split_num)), \u0027rb\u0027) as f:\n        vecs_temp \u003d pickle.load(f)\n    if i \u003d\u003d 0:\n        vecs \u003d vecs_temp\n    else:\n        vecs \u003d np.hstack((vecs, vecs_temp[:, :]))\n    del vecs_temp\n    gc.collect()\n    print(\u0027\\r\u003e\u003e\u003e\u003e index_vecs{}_of_{}.pkl load done...\u0027.format(i+1, split_num), end\u003d\u0027\u0027)\nprint(\u0027\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e\u003e\u003e load test vecs from pkl...\u0027)\nsplit_num \u003d 8\nfor i in range(split_num):\n    # qvecs_temp \u003d np.loadtxt(open(os.path.join(get_data_root(), \u0027test_vecs{}_of_{}.csv\u0027.format(i+1, split_num)), \"rb\"),\n    #                         delimiter\u003d\",\", skiprows\u003d0)\n    with open(os.path.join(get_data_root(), \u0027test_vecs{}_of_{}.pkl\u0027.format(i+1, split_num)), \u0027rb\u0027) as f:\n        qvecs_temp \u003d pickle.load(f)\n    if i \u003d\u003d 0:\n        qvecs \u003d qvecs_temp\n    else:\n        qvecs \u003d np.hstack((qvecs, qvecs_temp[:, :]))\n    del qvecs_temp\n    gc.collect()\n    print(\u0027\\r\u003e\u003e\u003e\u003e test_vecs{}_of_{}.pkl load done...\u0027.format(i+1, split_num), end\u003d\u0027\u0027)\nprint(\u0027\u0027)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# compute whitening\nif whitening is not None:\n    start \u003d time.time()\n    if \u0027Lw\u0027 in net.meta and whitening in net.meta[\u0027Lw\u0027]:\n        print(\u0027\u003e\u003e {}: Whitening is precomputed, loading it...\u0027.format(whitening))\n        if len(ms) \u003e 1:\n            Lw \u003d net.meta[\u0027Lw\u0027][whitening][\u0027ms\u0027]\n        else:\n            Lw \u003d net.meta[\u0027Lw\u0027][whitening][\u0027ss\u0027]\n    else:\n        # if we evaluate networks from path we should save/load whitening\n        # not to compute it every time\n        if network_path is not None:\n            whiten_fn \u003d network_path + \u0027_{}_whiten\u0027.format(whitening)\n            if len(ms) \u003e 1:\n                whiten_fn +\u003d \u0027_ms\u0027\n            whiten_fn +\u003d \u0027.pth\u0027\n        else:\n            whiten_fn \u003d None\n        if whiten_fn is not None and os.path.isfile(whiten_fn):\n            print(\u0027\u003e\u003e {}: Whitening is precomputed, loading it...\u0027.format(whitening))\n            Lw \u003d torch.load(whiten_fn)\n        else:\n            print(\u0027\u003e\u003e {}: Learning whitening...\u0027.format(whitening))\n            # extract whitening vectors\n            print(\u0027\u003e\u003e {}: Extracting...\u0027.format(whitening))\n            # wvecs \u003d vecs\n            wvecs \u003d np.hstack((vecs, qvecs))\n            # learning whitening\n            print(\u0027\u003e\u003e {}: Learning...\u0027.format(whitening))\n            m, P \u003d pcawhitenlearn(wvecs)\n            Lw \u003d {\u0027m\u0027: m, \u0027P\u0027: P}\n            del wvecs\n            gc.collect()\n            # saving whitening if whiten_fn exists\n            if whiten_fn is not None:\n                print(\u0027\u003e\u003e {}: Saving to {}...\u0027.format(whitening, whiten_fn))\n                torch.save(Lw, whiten_fn)\n    print(\u0027\u003e\u003e {}: elapsed time: {}\u0027.format(whitening, htime(time.time() - start)))\nelse:\n    Lw \u003d None\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e apply PCA whiten...\u0027)\nif Lw is not None:\n    # whiten the vectors and shrinkage\n    vecs_lw \u003d np.dot(Lw[\u0027P\u0027], vecs - Lw[\u0027m\u0027])\n    print(\u0027\u003e\u003e index vecs PCA whitening done...\u0027)\n    qvecs_lw \u003d np.dot(Lw[\u0027P\u0027], qvecs - Lw[\u0027m\u0027])\n    print(\u0027\u003e\u003e test vecs PCA whitening done...\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e\u003e\u003e save index PCA whiten vecs to pkl...\u0027)\nsplit_num \u003d 8\nextract_num \u003d int(len(images) / split_num)\nnum_list \u003d list(range(0, len(images)+1, extract_num))\nnum_list[-1] \u003d len(images)\nfor i in range(split_num):\n    vecs_file_path \u003d os.path.join(get_data_root(), \u0027index_PCA_whiten_vecs{}_of_{}.pkl\u0027.format(i+1, split_num))\n    vecs_file \u003d open(vecs_file_path, \u0027wb\u0027)\n    pickle.dump(vecs_lw[:, num_list[i]:num_list[i+1]], vecs_file)\n    vecs_file.close()\n    print(\u0027\\r\u003e\u003e\u003e\u003e index_PCA_whiten_vecs{}_of_{}.pkl save done...\u0027.format(i+1, split_num), end\u003d\u0027\u0027)\nprint(\u0027\u0027)\n\nprint(\u0027\u003e\u003e\u003e\u003e save test PCA whiten vecs to pkl...\u0027)\nsplit_num \u003d 8\nextract_num \u003d int(len(qimages) / split_num)\nnum_list \u003d list(range(0, len(qimages)+1, extract_num))\nnum_list[-1] \u003d len(qimages)\nfor i in range(split_num):\n    qvecs_file_path \u003d os.path.join(get_data_root(), \u0027test_PCA_whiten_vecs{}_of_{}.pkl\u0027.format(i+1, split_num))\n    qvecs_file \u003d open(qvecs_file_path, \u0027wb\u0027)\n    pickle.dump(qvecs_lw[:, num_list[i]:num_list[i+1]], qvecs_file)\n    qvecs_file.close()\n    print(\u0027\\r\u003e\u003e\u003e\u003e test_PCA_whiten_vecs{}_of_{}.pkl save done...\u0027.format(i+1, split_num), end\u003d\u0027\u0027)\nprint(\u0027\u0027)\n\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\u0027\u003e\u003e\u003e\u003e load index PCA whiten vecs from pkl...\u0027)\nfor i in range(split_num):\n    with open(os.path.join(get_data_root(), \u0027index_PCA_whiten_vecs{}_of_{}.pkl\u0027.format(i+1, split_num)), \u0027rb\u0027) as f:\n        vecs_temp \u003d pickle.load(f)\n    if i \u003d\u003d 0:\n        vecs_lw \u003d vecs_temp\n    else:\n        vecs_lw \u003d np.hstack((vecs_lw, vecs_temp[:, :]))\n    del vecs_temp\n    gc.collect()\n    print(\u0027\\r\u003e\u003e\u003e\u003e index_PCA_whiten_vecs{}_of_{}.pkl load done...\u0027.format(i+1, split_num), end\u003d\u0027\u0027)\nprint(\u0027\u0027)\n\nprint(\u0027\u003e\u003e\u003e\u003e load test PCA whiten vecs from pkl...\u0027)\nfor i in range(split_num):\n    with open(os.path.join(get_data_root(), \u0027test_PCA_whiten_vecs{}_of_{}.pkl\u0027.format(i+1, split_num)), \u0027rb\u0027) as f:\n        qvecs_temp \u003d pickle.load(f)\n    if i \u003d\u003d 0:\n        qvecs_lw \u003d qvecs_temp\n    else:\n        qvecs_lw \u003d np.hstack((qvecs_lw, qvecs_temp[:, :]))\n    del qvecs_temp\n    gc.collect()\n    print(\u0027\\r\u003e\u003e\u003e\u003e test_PCA_whiten_vecs{}_of_{}.pkl load done...\u0027.format(i+1, split_num), end\u003d\u0027\u0027)\nprint(\u0027\u0027)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# extract principal components and normalization\nvecs \u003d vecs_lw\nqvecs \u003d qvecs_lw\ndel vecs_lw, qvecs_lw\ngc.collect()\nratio \u003d 1\nvecs  \u003d vecs[:int(vecs.shape[0]*ratio), :]\nvecs \u003d vecs / (np.linalg.norm(vecs, ord\u003d2, axis\u003d0, keepdims\u003dTrue) + 1e-6)\nqvecs \u003d qvecs[:int(qvecs.shape[0]*ratio), :]\nqvecs \u003d qvecs / (np.linalg.norm(qvecs, ord\u003d2, axis\u003d0, keepdims\u003dTrue) + 1e-6)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# kNN search\nprint(\u0027\u003e\u003e {}: Evaluating...\u0027.format(dataset))\nvecs_T \u003d np.zeros((vecs.shape[1], vecs.shape[0])).astype(\u0027float32\u0027)\nvecs_T[:] \u003d vecs.T[:]\nimport faiss  # place it in the file top will cause network load so slowly\nres \u003d faiss.StandardGpuResources()\nkNN_on_gpu_id \u003d 0\ntop_num \u003d 100\nk \u003d 100\n\nsplit_num \u003d 1\nfor i in range(split_num):\n    # scores \u003d np.dot(vecs.T, qvecs[:, int(qvecs.shape[1]/split_num*i):int(qvecs.shape[1]/split_num*(i+1))])\n    # ranks \u003d np.argsort(-scores, axis\u003d0)    \n    print(\u0027\u003e\u003e find nearest neighbour, k: {}, top_num: {}\u0027.format(k, top_num))\n    index \u003d faiss.IndexFlatL2(vecs.shape[0])\n    gpu_index \u003d faiss.index_cpu_to_gpu(res, kNN_on_gpu_id, index)\n    gpu_index.add(vecs_T)\n    query_vecs \u003d qvecs[:, int(qvecs.shape[1] / split_num * i):int(qvecs.shape[1] / split_num * (i + 1))]\n    qvecs_T \u003d np.zeros((query_vecs.shape[1], query_vecs.shape[0])).astype(\u0027float32\u0027)\n    qvecs_T[:] \u003d query_vecs.T[:]\n    _, ranks \u003d gpu_index.search(qvecs_T, k)\n    ranks \u003d ranks.T\n    if i \u003d\u003d 0:\n        ranks_top_100 \u003d ranks[:top_num, :]\n    else:\n        ranks_top_100 \u003d np.hstack((ranks_top_100, ranks[:top_num, :]))\n    # del scores, ranks\n    del index, query_vecs, qvecs_T\n    gc.collect()\n    print(\u0027\\r\u003e\u003e\u003e\u003e kNN search {} nearest neighbour {}/{} done...\u0027.format(top_num, i + 1, split_num), end\u003d\u0027\u0027)\ndel qvecs\ngc.collect()\nprint(\u0027\u0027)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# query expansion\nQEk \u003d 50\nalpha \u003d 12./2\niter \u003d 1\nQE_weight \u003d ((np.arange(QEk, 0, -1) / QEk).reshape(1, QEk, 1) ** alpha)\nranks_split_num \u003d 50\nprint(\u0027\u003e\u003e Query expansion: k: {}, alpha: {}, iteration: {}\u0027.format(QEk, alpha, iter))\nfor i in range(ranks_split_num):\n    ranks_split \u003d ranks[:QEk, int(ranks.shape[1] / ranks_split_num * i):\n                           int(ranks.shape[1] / ranks_split_num * (i + 1))]\n    top_k_vecs \u003d vecs[:, ranks_split]  # shape \u003d (2048, QEk, query_split_size)\n    qvecs_temp \u003d (top_k_vecs * QE_weight).sum(axis\u003d1)\n    qvecs_temp \u003d qvecs_temp / (np.linalg.norm(qvecs_temp, ord\u003d2, axis\u003d0, keepdims\u003dTrue) + 1e-6)\n    if i \u003d\u003d 0:\n        qvecs \u003d qvecs_temp\n    else:\n        qvecs \u003d np.hstack((qvecs, qvecs_temp))\n    del ranks_split, top_k_vecs, qvecs_temp\n    gc.collect()\n    print(\u0027\\r\u003e\u003e\u003e\u003e calculate new query vectors {}/{} done...\u0027.format(i+1, ranks_split_num), end\u003d\u0027\u0027)\nprint(\u0027\u0027)\nqe_iter_qvecs_path \u003d os.path.join(get_data_root(), \u0027QE_iter{}_qvecs.pkl\u0027.format(iter))\nqe_iter_qvecs_file \u003d open(qe_iter_qvecs_path, \u0027wb\u0027)\npickle.dump(qvecs, qe_iter_qvecs_file)\nqe_iter_qvecs_file.close()\nprint(\u0027\u003e\u003e\u003e\u003e QE_iter{}_qvecs.pkl save done...\u0027.format(iter))\ndel ranks\ngc.collect()\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# save to csv file\nprint(\"\u003e\u003e save to submission.csv file...\")\nsubmission_file \u003d open(os.path.join(get_data_root(), \u0027submission.csv\u0027), \u0027w\u0027)\nwriter \u003d csv.writer(submission_file)\ntest_mark_file \u003d open(test_mark_add_path, \u0027r\u0027)\ncsvreader \u003d csv.reader(test_mark_file)\ncnt \u003d 0\nwriter.writerow([\u0027id\u0027, \u0027images\u0027])\nfor index, line in enumerate(csvreader):\n    (flag, img_name) \u003d line[:2]\n    if flag \u003d\u003d \u00271\u0027:\n        select \u003d []\n        for i in range(top_num):\n            select.append(images[int(ranks_top_100[i, cnt])].split(\u0027/\u0027)[-1].split(\u0027.jpg\u0027)[0])\n        cnt +\u003d 1\n        writer.writerow([img_name.split(\u0027/\u0027)[-1].split(\u0027.jpg\u0027)[0], \u0027 \u0027.join(select)])\n    else:\n        # random_list \u003d random.sample(range(0, len(images)), top_num)\n        random_list \u003d np.random.choice(len(images), top_num, replace\u003dFalse)\n        select \u003d []\n        for i in range(top_num):\n            select.append(images[random_list[i]].split(\u0027/\u0027)[-1].split(\u0027.jpg\u0027)[0])\n        writer.writerow([img_name.split(\u0027/\u0027)[-1].split(\u0027.jpg\u0027)[0], \u0027 \u0027.join(select)])\n    if cnt % 10 \u003d\u003d 0 or cnt \u003d\u003d len(qimages):\n        print(\u0027\\r\u003e\u003e\u003e\u003e {}/{} done...\u0027.format(cnt, len(qimages)), end\u003d\u0027\u0027)\nsubmission_file.close()\ntest_mark_file.close()\nprint(\u0027\u0027)\nprint(\u0027\u003e\u003e {}: elapsed time: {}\u0027.format(dataset, htime(time.time()-start)))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "pycharm-68d9976a",
      "language": "python",
      "display_name": "PyCharm (cnnimageretrieval-end2end-google_landmarks_retrieval)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}